const robot = require('robotjs');
const activeWin = require('active-win');
const { GlobalKeyboardListener } = require('node-global-key-listener');
const sharp = require('sharp');
const fs = require('fs');
const vision = require("@google-cloud/vision");
const screenshot = require('screenshot-desktop')
const screenshotPath = "./screenshot.png";
let capturedKeys = "";

async function proceedGoogleVision() {
    try {
        const client = new vision.ImageAnnotatorClient({
            keyFilename: "./imnokoltest-e512687e43b9.json"
        })
        const [result] = await client.textDetection(screenshotPath);
        const texts = result.textAnnotations;
        return texts.map(o => ({
            text: o.description,
            bbox: {
                x0: o.boundingPoly.vertices[0].x,
                y0: o.boundingPoly.vertices[1].y,
                x1: o.boundingPoly.vertices[1].x,
                y1: o.boundingPoly.vertices[2].y
            }
        }))
    } catch (e) {
        console.log(e);
    }
}


export const getDesktopData = async (callback): Promise<any> => {
    capturedKeys = capturedKeys.trim();

    const mousePos = robot.getMousePos();
    const displays = await screenshot.listDisplays();
    const activeDisplay = displays.find((display) => {
        return mousePos.x >= display.left && mousePos.x <= display.right && mousePos.y >= display.top && mousePos.y <= display.bottom;
    });

    // screenshot({ format: 'png' }).then((img) => {
    //     fs.writeFileSync('screenshot2.png', img);
    // }).catch((err) => {
    //     console.log(err);
    // })

    const activeWindow = await activeWin();

    if (!activeWindow) {
        throw new Error('No active window found');
    }

    let { bounds } = activeWindow;

    const desktopScaleFactor = activeDisplay?.dpiScale ?? 1; // determine thisasdasd
    bounds = {
        x: bounds.x * desktopScaleFactor,
        y: bounds.y * desktopScaleFactor,
        width: bounds.width * desktopScaleFactor,
        height: bounds.height * desktopScaleFactor,
    };


    const img = robot.screen.capture(bounds.x, bounds.y, bounds.width, bounds.height);

    const pngBuffer = await sharp(img.image, {
        raw: {
            width: img.width,
            height: img.height,
            channels: 4
        }
    }).png().toBuffer();

    fs.writeFileSync(screenshotPath, pngBuffer);
    const cursorPosScreen = robot.getMousePos();
    const cursorPos = {
        x: ((cursorPosScreen.x * desktopScaleFactor) - bounds.x),
        y: ((cursorPosScreen.y * desktopScaleFactor) - bounds.y)
    };

    // const worker = await createWorker("eng");
    // const ret = await worker.recognize(pngBuffer);
    // let newText = ret.data.text.trim();
    // let words = ret.data.words;
    const gCloudTest = await proceedGoogleVision();
    let newText = gCloudTest.map(o => o.text).join(" ");
    let words = gCloudTest;


    let results: any[] = [];
    for (let word of words) {

        if (word.text.length > 100) continue;

        const x1 = word.bbox.x0
        const y1 = word.bbox.y0;
        const width = (word.bbox.x1 - word.bbox.x0);
        results.push({
            x: x1,
            y: y1,
            width,
            height: word.bbox.y1 - word.bbox.y0,
            text: word.text,
        } as ScreenTextData);
    }

    // // order results by same line +-5 and then by x position
    // results = results.sort((o1, o2) => {
    //     const y1 = o1.y;
    //     const y2 = o2.y;
    //     const x1 = o1.x;
    //     const x2 = o2.x;

    //     if (Math.abs(y1 - y2) <= 2) {
    //         return x1 - x2;
    //     }

    //     return y1 - y2;
    // });


    // find result that is closest to cursor by checking if cursor is within x and y of the result
    let textNearCursor: ScreenTextData | undefined = undefined;
    for (let result of results) {
        const x1 = result.x;
        const y1 = result.y;
        const x2 = x1 + result.width;
        const y2 = y1 + result.height;

        if (cursorPos.x >= x1 && cursorPos.x <= x2 && cursorPos.y >= y1 && cursorPos.y <= y2) {
            textNearCursor = result;
            break;
        }
    }

    // find result that is closest to captured keys starting from all words to seek a match with the captured keys then remove one word at a time until a match is found  
    const mergedWords = results.map(o => o.text).join(" ");
    let capturedKeysCopy = capturedKeys ?? textNearCursor?.text ?? "";
    let foundWords = "";

    while (capturedKeysCopy.length > 0) {
        if (mergedWords.includes(capturedKeysCopy)) {
            foundWords = capturedKeysCopy;
            break;
        }

        capturedKeysCopy = capturedKeysCopy.substring(0, capturedKeysCopy.length - 1);
    }

    const splittedCapturedKeys = foundWords.split(" ");
    const lastWord = splittedCapturedKeys[splittedCapturedKeys.length - 1];
    const positionsWithLastWord = results.filter(o => o.text == lastWord).map(o => results.indexOf(o));

    // iterate over positionsWithLastWord by checking if the word before  until one left
    let exact_positions_word: ScreenTextData | undefined = undefined;

    for (let i = positionsWithLastWord.length - 1; i >= 0; i--) {
        const position = positionsWithLastWord[i];
        const word = results[position];
        const wordBefore = results[position - 1];

        if (wordBefore && wordBefore.text == splittedCapturedKeys[splittedCapturedKeys.length - 2]) {
            exact_positions_word = word;
            break;
        }
    }

    const result = {
        date: new Date(), ...{
            text_screen: newText,
            text_of_interest: newText.split(exact_positions_word?.text ?? textNearCursor?.text ?? "")[0],
            cursor_position: cursorPos,
            last_written_text: capturedKeys,
            // words_bounding_boxes: results,
            text_near_cursor: textNearCursor,
            caret_position: exact_positions_word,
        }
    };
    // await worker.terminate();
    capturedKeys = "";
    if(callback) callback(result);
    return result;
};

export function startObserving(callback: (data: any) => void) {
    const keyListener = new GlobalKeyboardListener();

    keyListener.addListener((e) => {
        if (e.state.toLowerCase() != "up") {
            return;
        }

        const name = e.name.toLowerCase();

        if (name == "backspace") {
            capturedKeys = capturedKeys.substring(0, capturedKeys.length - 1);
        }

        if (name == "space") {
            capturedKeys += " ";
        }

        if (name == "enter") {
            capturedKeys += "\n";
        }

        if (name == "tab") {
            capturedKeys += " ";
        }

        if (e.name.length == 1) {
            capturedKeys += name;
        }

        debounce(callback);
    });
}

let timeout: any = undefined;
function debounce(callback: (data: any) => void) {
    if (timeout) {
        clearTimeout(timeout);
    }

    timeout = setTimeout(() => {
        getDesktopData(callback);
    }, 2000);
}


interface ScreenTextData {
    text: string;
    x: number;
    y: number;
    width: number;
    height: number;
}
